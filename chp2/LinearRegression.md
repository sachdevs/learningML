#2 - Linear Regression
##Simple linear regression
- Used to model relationship between one response variable and one explanatory variable
- Assumes linear relationship exists between response(Price) and explanatory vars(Diameter) called a *hyperplane*
- to test whether or not variables are independent use chi square tests of independence
- *hyperplane* - subspace that has one var less than the space that contains it
- *subspace* - (remember lin alg) Let V be a vector space over the field K, and let W be a subset of V. Then W is a subspace if and only if W satisfies the following three conditions:
  1. The zero vector, 0, is in W.
  2. If u and v are elements of W, then the sum u + v is an element of W;
  3. If u is an element of W and c is a scalar from K, then the product cu is an element of W
- for one explanatory var and one response var (=> 2 dimensions), hyperplane has to be 1-dimensional aka line.
- alpha - y-int
- beta - slope
- sklearn.linear_model.LinearRegression class is an estimator
- called method of least square cause minimizing sum of square of y-difference of points from line (residuals)

##Evaluating fitness of model with cost function
- *cost function* used to messure error in model
- *residuals* difference in prediction by model and irl
- *prediction errors* difference between predicted vals and observed vals
- *residual sum of squares* should be minimized:
  - aka mean of predict - y squared
```
SS _res = sum(1, n, i, (y _i - f(x _i))^2)
```